{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70785f12-299b-4c6a-a302-4c743fc85e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "datapath = \"/net/tscratch/people/plgjsikora/data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2795dd20-0b0a-4ee9-bbac-fee48b755465",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "class SHLDataProviderRaw:\n",
    "  def __init__(self, root_path:str, flag: str, mode: str, location: str = \"Hips\", sensor: str = \"Acc_x\", silent = True, four_locs = False):\n",
    "    '''\n",
    "    | Setup data provider for SHL 2025 Challenge\n",
    "    | Args:\n",
    "    | root_path: path to root data folder\n",
    "    | flag: one of train, validation, test\n",
    "    | mode: one of singlefile, singlefolder, all\n",
    "    | location: where to load from (Hips/Bag etc)\n",
    "    | sensor: which file to load (Acc_x/Mag_z etc)\n",
    "    | silent: supress print statements\n",
    "    | Example usage:\n",
    "    | provider = SHLDataProviderRaw(datapath, \"train\", \"singlefolder\", location=\"Bag\")\n",
    "    | x, y = provider.load_data()\n",
    "    '''\n",
    "    self.mode = mode.lower()\n",
    "    self.flag = flag.lower()\n",
    "    self.location = location.capitalize()\n",
    "    self.sensor = sensor.capitalize()\n",
    "    self.silent = silent\n",
    "    if self.flag not in [\"test\", \"train\", \"validation\"]:\n",
    "      raise ValueError(f\"Unexpected flag received: got {self.flag}\")\n",
    "    if self.mode not in [\"singlefile\", \"singlefolder\", \"all\"]:\n",
    "      raise ValueError(f\"Unexpected mode received: got {self.mode}\")\n",
    "    if self.flag == 'train' and four_locs:\n",
    "      self.datapath = os.path.join(root_path, \"train_4_locations\")\n",
    "    else:\n",
    "      self.datapath = os.path.join(root_path, self.flag)\n",
    "\n",
    "  def load_data(self):\n",
    "    if self.mode == \"singlefile\":\n",
    "      x_data, y_data = self._load_from_file()\n",
    "    elif self.mode == \"singlefolder\":\n",
    "      x_data, y_data = self._load_from_folder()\n",
    "    elif self.mode == \"all\":\n",
    "      x_data, y_data = self._load_all()\n",
    "    return np.array(x_data), np.array(y_data)\n",
    "\n",
    "  def _load_label_file(self, labelpath):\n",
    "      if not self.silent:\n",
    "        print(f\"Loading labels from: {labelpath}\")\n",
    "      y_data = np.loadtxt(labelpath, dtype=int)\n",
    "      y_data[np.isnan(y_data)] = 1\n",
    "      y_data = np.median(y_data, axis=1).astype(int)\n",
    "      y_data = y_data - 1\n",
    "      y_data = to_categorical(y_data, len(np.unique(y_data)))\n",
    "      return y_data\n",
    "\n",
    "  def _load_location_data(self, path):\n",
    "      def load_txt_csv(path):\n",
    "            if not self.silent:\n",
    "                print(f\"Loading data from: {path}\")\n",
    "            if self.flag == 'test':\n",
    "                np_data = np.loadtxt(path, dtype=np.float32, delimiter=\",\")\n",
    "            else:\n",
    "                df = pd.read_csv(path, header=None, delim_whitespace=True, engine='python')\n",
    "                np_data = df.to_numpy()\n",
    "            return np_data\n",
    "      acc_x = load_txt_csv(f'{path}/Acc_x.txt')\n",
    "      acc_y = load_txt_csv(f'{path}/Acc_y.txt')\n",
    "      acc_z = load_txt_csv(f'{path}/Acc_z.txt')\n",
    "      gyr_x = load_txt_csv(f'{path}/Gyr_x.txt')\n",
    "      gyr_y = load_txt_csv(f'{path}/Gyr_y.txt')\n",
    "      gyr_z = load_txt_csv(f'{path}/Gyr_z.txt')\n",
    "      mag_x = load_txt_csv(f'{path}/Mag_x.txt')\n",
    "      mag_y = load_txt_csv(f'{path}/Mag_y.txt')\n",
    "      mag_z = load_txt_csv(f'{path}/Mag_z.txt')\n",
    "      data = np.stack([acc_x, acc_y, acc_z, gyr_x, gyr_y, gyr_z, mag_x, mag_y, mag_z], axis=2)\n",
    "      return data\n",
    "  \n",
    "  def _load_from_folder(self):\n",
    "      '''\n",
    "      Load all sensors from folder (location)\n",
    "      '''\n",
    "      if self.flag == \"test\":\n",
    "          filepath = self.datapath\n",
    "          data = self._load_location_data(filepath)\n",
    "          return data\n",
    "      else:\n",
    "          filepath = os.path.join(self.datapath, self.location)\n",
    "          labels = self._load_label_file(os.path.join(filepath, \"Label.txt\"))\n",
    "          data = self._load_location_data(filepath)\n",
    "          return data, labels\n",
    "  def _load_all(self):\n",
    "      if self.flag == 'test':\n",
    "          data = self._load_from_folder()\n",
    "          return data\n",
    "      self.location = \"Hips\"\n",
    "      hips_data, hips_labels = self._load_from_folder()\n",
    "      self.location = \"Torso\"\n",
    "      torso_data, torso_labels = self._load_from_folder()\n",
    "      self.location = \"Bag\"\n",
    "      bag_data, bag_labels = self._load_from_folder()\n",
    "      self.location = \"Hand\"\n",
    "      hand_data, hand_labels = self._load_from_folder()\n",
    "      data = np.concatenate([hips_data, torso_data, bag_data, hand_data], axis = 0)\n",
    "      labels = np.concatenate([hips_labels, torso_labels, bag_labels, hand_labels], axis=0)\n",
    "      return data, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c587bc97-d6eb-4a9b-a506-dd4128f6fc86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, LSTM, multiply, concatenate, Activation, Masking, Reshape\n",
    "from tensorflow.keras.layers import Conv1D, BatchNormalization, GlobalAveragePooling1D, Permute, Dropout\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "class ModelProvider:\n",
    "  def __init__(self, seq_len = 500, nfeatures = 9, nclasses = 8):\n",
    "    '''\n",
    "    | Initializer model provider\n",
    "    | Args:\n",
    "    | seq_len - length of time series analysed\n",
    "    | nfeatures - number of features of each time point\n",
    "    | nclasses - number of target classes\n",
    "    | Example usage:\n",
    "    | provider = ModelProvider(500, 9, 8)\n",
    "    | model = provider.get_model()\n",
    "    '''\n",
    "    self.seq_len = seq_len\n",
    "    self.nfeatures = nfeatures\n",
    "    self.nclasses = nclasses\n",
    "    self.model = None\n",
    "\n",
    "\n",
    "  def build_model(self):\n",
    "    '''\n",
    "    | Build model for SHL Challenge\n",
    "    | Reimplementation of a model from https://github.com/titu1994/MLSTM-FCN for newer keras\n",
    "    '''\n",
    "\n",
    "    def squeeze_excite_block(input):\n",
    "      ''' Create a squeeze-excite block\n",
    "      Args:\n",
    "          input: input tensor\n",
    "          filters: number of output filters\n",
    "          k: width factor\n",
    "\n",
    "      Returns: a keras tensor\n",
    "      '''\n",
    "      filters = input.shape[-1] # channel_axis = -1 for TF\n",
    "\n",
    "      se = GlobalAveragePooling1D()(input)\n",
    "      se = Reshape((1, filters))(se)\n",
    "      se = Dense(filters // 16,  activation='relu', kernel_initializer='he_normal', use_bias=False)(se)\n",
    "      se = Dense(filters, activation='sigmoid', kernel_initializer='he_normal', use_bias=False)(se)\n",
    "      se = multiply([input, se])\n",
    "      return se\n",
    "\n",
    "    ip = Input(shape=(self.seq_len, self.nfeatures), dtype=float)\n",
    "    x = Permute((2, 1))(ip)\n",
    "    x = Masking()(ip)\n",
    "    x = LSTM(8)(x)\n",
    "    x = Dropout(0.4)(x)\n",
    "\n",
    "    y = Conv1D(128, 8, padding='same', kernel_initializer='he_uniform', data_format='channels_last', kernel_regularizer=regularizers.L2(1e-4))(ip)\n",
    "    y = BatchNormalization()(y)\n",
    "    y = Activation('relu')(y)\n",
    "    y = squeeze_excite_block(y)\n",
    "    y = Dropout(0.4)(y)\n",
    "\n",
    "    y = Conv1D(256, 5, padding='same', kernel_initializer='he_uniform', data_format='channels_last', kernel_regularizer=regularizers.L2(1e-4))(y)\n",
    "    y = BatchNormalization()(y)\n",
    "    y = Activation('relu')(y)\n",
    "    y = squeeze_excite_block(y)\n",
    "    y = Dropout(0.4)(y)\n",
    "\n",
    "    y = Conv1D(128, 3, padding='same', kernel_initializer='he_uniform', data_format='channels_last', kernel_regularizer=regularizers.L2(1e-4))(y)\n",
    "    y = BatchNormalization()(y)\n",
    "    y = Activation('relu')(y)\n",
    "    y = GlobalAveragePooling1D()(y)\n",
    "    y = Dropout(0.4)(y)\n",
    "\n",
    "    x = concatenate([x, y])\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    x = Dropout(0.4)(x)\n",
    "    out = Dense(self.nclasses, activation='softmax')(x)\n",
    "    self.model = Model(ip, out)\n",
    "\n",
    "  def from_weights(self, weightpath):\n",
    "    '''\n",
    "    Get model from existing weights\n",
    "    '''\n",
    "    self.build_model()\n",
    "    self.model.load_weights(weightpath)\n",
    "    return self.model\n",
    "\n",
    "  def get_model(self):\n",
    "    if self.model is None:\n",
    "      self.build_model()\n",
    "    return self.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "38e8b1e1-d783-46c8-b388-cabee7f17020",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-22 18:27:57.229918: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38668 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:47:00.0, compute capability: 8.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 500, 9)]     0           []                               \n",
      "                                                                                                  \n",
      " conv1d (Conv1D)                (None, 500, 128)     9344        ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 500, 128)    512         ['conv1d[0][0]']                 \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 500, 128)     0           ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " global_average_pooling1d (Glob  (None, 128)         0           ['activation[0][0]']             \n",
      " alAveragePooling1D)                                                                              \n",
      "                                                                                                  \n",
      " reshape (Reshape)              (None, 1, 128)       0           ['global_average_pooling1d[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 1, 8)         1024        ['reshape[0][0]']                \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 1, 128)       1024        ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " multiply (Multiply)            (None, 500, 128)     0           ['activation[0][0]',             \n",
      "                                                                  'dense_1[0][0]']                \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 500, 128)     0           ['multiply[0][0]']               \n",
      "                                                                                                  \n",
      " conv1d_1 (Conv1D)              (None, 500, 256)     164096      ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 500, 256)    1024        ['conv1d_1[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, 500, 256)     0           ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " global_average_pooling1d_1 (Gl  (None, 256)         0           ['activation_1[0][0]']           \n",
      " obalAveragePooling1D)                                                                            \n",
      "                                                                                                  \n",
      " reshape_1 (Reshape)            (None, 1, 256)       0           ['global_average_pooling1d_1[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 1, 16)        4096        ['reshape_1[0][0]']              \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 1, 256)       4096        ['dense_2[0][0]']                \n",
      "                                                                                                  \n",
      " multiply_1 (Multiply)          (None, 500, 256)     0           ['activation_1[0][0]',           \n",
      "                                                                  'dense_3[0][0]']                \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 500, 256)     0           ['multiply_1[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_2 (Conv1D)              (None, 500, 128)     98432       ['dropout_2[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 500, 128)    512         ['conv1d_2[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " masking (Masking)              (None, 500, 9)       0           ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " activation_2 (Activation)      (None, 500, 128)     0           ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " lstm (LSTM)                    (None, 8)            576         ['masking[0][0]']                \n",
      "                                                                                                  \n",
      " global_average_pooling1d_2 (Gl  (None, 128)         0           ['activation_2[0][0]']           \n",
      " obalAveragePooling1D)                                                                            \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 8)            0           ['lstm[0][0]']                   \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 128)          0           ['global_average_pooling1d_2[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 136)          0           ['dropout[0][0]',                \n",
      "                                                                  'dropout_3[0][0]']              \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 128)          17536       ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_4 (Dropout)            (None, 128)          0           ['dense_4[0][0]']                \n",
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, 8)            1032        ['dropout_4[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 303,304\n",
      "Trainable params: 302,280\n",
      "Non-trainable params: 1,024\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "mprovider = ModelProvider(nfeatures = 9)\n",
    "#model_path = \"/net/tscratch/people/plgjsikora/models/MLSTM_athena__all_vali_vali.weights.h5\"\n",
    "#model = mprovider.from_weights(model_path)\n",
    "model = mprovider.get_model()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4bf1d4b-d3a3-43e1-98db-fc38ac6ad8ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading labels from: /net/tscratch/people/plgjsikora/data/train/Hips/Label.txt\n",
      "Loading data from: /net/tscratch/people/plgjsikora/data/train/Hips/Acc_x.txt\n",
      "Loading data from: /net/tscratch/people/plgjsikora/data/train/Hips/Acc_y.txt\n",
      "Loading data from: /net/tscratch/people/plgjsikora/data/train/Hips/Acc_z.txt\n",
      "Loading data from: /net/tscratch/people/plgjsikora/data/train/Hips/Gyr_x.txt\n",
      "Loading data from: /net/tscratch/people/plgjsikora/data/train/Hips/Gyr_y.txt\n",
      "Loading data from: /net/tscratch/people/plgjsikora/data/train/Hips/Gyr_z.txt\n",
      "Loading data from: /net/tscratch/people/plgjsikora/data/train/Hips/Mag_x.txt\n",
      "Loading data from: /net/tscratch/people/plgjsikora/data/train/Hips/Mag_y.txt\n",
      "Loading data from: /net/tscratch/people/plgjsikora/data/train/Hips/Mag_z.txt\n",
      "Loading labels from: /net/tscratch/people/plgjsikora/data/train/Torso/Label.txt\n",
      "Loading data from: /net/tscratch/people/plgjsikora/data/train/Torso/Acc_x.txt\n",
      "Loading data from: /net/tscratch/people/plgjsikora/data/train/Torso/Acc_y.txt\n",
      "Loading data from: /net/tscratch/people/plgjsikora/data/train/Torso/Acc_z.txt\n",
      "Loading data from: /net/tscratch/people/plgjsikora/data/train/Torso/Gyr_x.txt\n",
      "Loading data from: /net/tscratch/people/plgjsikora/data/train/Torso/Gyr_y.txt\n",
      "Loading data from: /net/tscratch/people/plgjsikora/data/train/Torso/Gyr_z.txt\n",
      "Loading data from: /net/tscratch/people/plgjsikora/data/train/Torso/Mag_x.txt\n",
      "Loading data from: /net/tscratch/people/plgjsikora/data/train/Torso/Mag_y.txt\n",
      "Loading data from: /net/tscratch/people/plgjsikora/data/train/Torso/Mag_z.txt\n",
      "Loading labels from: /net/tscratch/people/plgjsikora/data/train/Bag/Label.txt\n",
      "Loading data from: /net/tscratch/people/plgjsikora/data/train/Bag/Acc_x.txt\n",
      "Loading data from: /net/tscratch/people/plgjsikora/data/train/Bag/Acc_y.txt\n",
      "Loading data from: /net/tscratch/people/plgjsikora/data/train/Bag/Acc_z.txt\n",
      "Loading data from: /net/tscratch/people/plgjsikora/data/train/Bag/Gyr_x.txt\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "dprovider = SHLDataProviderRaw(datapath, \"train\", \"all\", silent=False)\n",
    "x, y = dprovider.load_data()\n",
    "\n",
    "dprovider_val = SHLDataProviderRaw(datapath, \"validation\", \"all\", silent=False)\n",
    "x_2, y_2 = dprovider_val.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f55db3-55b7-4e57-9127-44ccba5bd605",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x.shape, y.shape)\n",
    "print(x_2.shape, y_2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb5efe2-5f0c-4504-96e9-bc6442e6df39",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_t = np.concatenate([x, x_2], axis=0)\n",
    "y_t = np.concatenate([y, y_2], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99789556-3b45-4a4b-9a66-f012efe0602c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_t.shape, y_t.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6075a8c-ecf0-4eb1-bcff-a80f57db8ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare data\n",
    "\n",
    "x_t[np.isnan(x_t)] = 0\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#x_n = x\n",
    "#print(x.T.shape)\n",
    "#for i in range(len(x.T)):\n",
    "  #print(np.max(x.T[i]), np.min(x.T[i]))\n",
    "  #x_n.T[i] = (x.T[i] - np.min(x.T[i])) / (np.max(x.T[i]) - np.min(x.T[i]))\n",
    "  #print(\"-----------------------------\")\n",
    "#print(x_n.shape)\n",
    "#print(np.min(x_n), np.max(x_n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0edaba0b-f8e7-411b-a0dd-5e9e570d5c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.model_selection import train_test_split\n",
    "#x_train, x_val, y_train, y_val = train_test_split(x_t, y_t, test_size = 0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a84a29-f834-4bd2-961d-22e52be34020",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8831b4-2ed5-4a30-be28-06ae101773d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile model\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.optimizers import Adam\n",
    "from datetime import datetime\n",
    "today = datetime.today().strftime('%Y-%m-%d')\n",
    "\n",
    "model_checkpoint_path =  f\"/net/tscratch/people/plgjsikora/models/MLSTM_athena_final{today}.weights.h5\"\n",
    "model_checkpoint = ModelCheckpoint(model_checkpoint_path, verbose=1, mode='auto',\n",
    "                                       monitor='val_accuracy', save_best_only=True, save_weights_only=True)\n",
    "\n",
    "optm = Adam(learning_rate=5e-4)\n",
    "\n",
    "callback_list = [model_checkpoint]\n",
    "model.compile(optimizer=optm, loss='categorical_crossentropy',  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c22fbaf-0d0b-45a7-aa31-26e0a49b81a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#history = model.fit(x_train, y_train, batch_size=256, epochs=50, verbose=1, shuffle=True, callbacks=callback_list, validation_freq=1, validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53520bd3-08fb-4f26-9bc8-ea2c0f31b072",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pickle\n",
    "#with open(f'/net/tscratch/people/plgjsikora/histfinal{today}.pickle', 'wb') as file_pi:\n",
    " #   pickle.dump(history.history, file_pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe24c699-8f4f-4d07-91e2-e3950b9f5df1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c207b3f-23f8-47dc-bd1e-5a41a9da7cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import matplotlib.pyplot as plt\n",
    "#disp.plot()\n",
    "#plt.show()\n",
    "#plt.savefig(f\"/net/tscratch/people/plgjsikora/cm{today}_valitovali_50epochs.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a53236a-8d56-4261-947d-c7ec67f271b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d485ac9-31a3-443b-9696-c2f3d937f450",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "556d6e64-c930-4d87-a943-deaecf49e352",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f60001f-421f-4a0d-923c-a61034f3692e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelProviderNoAntiOverfitting:\n",
    "  def __init__(self, seq_len = 500, nfeatures = 9, nclasses = 8):\n",
    "    '''\n",
    "    | Initializer model provider\n",
    "    | Args:\n",
    "    | seq_len - length of time series analysed\n",
    "    | nfeatures - number of features of each time point\n",
    "    | nclasses - number of target classes\n",
    "    | Example usage:\n",
    "    | provider = ModelProvider(500, 9, 8)\n",
    "    | model = provider.get_model()\n",
    "    '''\n",
    "    self.seq_len = seq_len\n",
    "    self.nfeatures = nfeatures\n",
    "    self.nclasses = nclasses\n",
    "    self.model = None\n",
    "\n",
    "\n",
    "  def build_model(self):\n",
    "    '''\n",
    "    | Build model for SHL Challenge\n",
    "    | Reimplementation of a model from https://github.com/titu1994/MLSTM-FCN for newer keras\n",
    "    '''\n",
    "\n",
    "    def squeeze_excite_block(input):\n",
    "      ''' Create a squeeze-excite block\n",
    "      Args:\n",
    "          input: input tensor\n",
    "          filters: number of output filters\n",
    "          k: width factor\n",
    "\n",
    "      Returns: a keras tensor\n",
    "      '''\n",
    "      filters = input.shape[-1] # channel_axis = -1 for TF\n",
    "\n",
    "      se = GlobalAveragePooling1D()(input)\n",
    "      se = Reshape((1, filters))(se)\n",
    "      se = Dense(filters // 16,  activation='relu', kernel_initializer='he_normal', use_bias=False)(se)\n",
    "      se = Dense(filters, activation='sigmoid', kernel_initializer='he_normal', use_bias=False)(se)\n",
    "      se = multiply([input, se])\n",
    "      return se\n",
    "\n",
    "    ip = Input(shape=(self.seq_len, self.nfeatures), dtype=float)\n",
    "    x = Permute((2, 1))(ip)\n",
    "    x = Masking()(ip)\n",
    "    x = LSTM(8)(x)\n",
    "\n",
    "    y = Conv1D(128, 8, padding='same', kernel_initializer='he_uniform', data_format='channels_last')(ip)\n",
    "    y = BatchNormalization()(y)\n",
    "    y = Activation('relu')(y)\n",
    "    y = squeeze_excite_block(y)\n",
    "\n",
    "    y = Conv1D(256, 5, padding='same', kernel_initializer='he_uniform', data_format='channels_last')(y)\n",
    "    y = BatchNormalization()(y)\n",
    "    y = Activation('relu')(y)\n",
    "    y = squeeze_excite_block(y)\n",
    "\n",
    "    y = Conv1D(128, 3, padding='same', kernel_initializer='he_uniform', data_format='channels_last')(y)\n",
    "    y = BatchNormalization()(y)\n",
    "    y = Activation('relu')(y)\n",
    "    y = GlobalAveragePooling1D()(y)\n",
    "\n",
    "    x = concatenate([x, y])\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    x = Dropout(0.4)(x)\n",
    "    out = Dense(self.nclasses, activation='softmax')(x)\n",
    "    self.model = Model(ip, out)\n",
    "\n",
    "  def from_weights(self, weightpath):\n",
    "    '''\n",
    "    Get model from existing weights\n",
    "    '''\n",
    "    self.build_model()\n",
    "    self.model.load_weights(weightpath)\n",
    "    return self.model\n",
    "\n",
    "  def get_model(self):\n",
    "    if self.model is None:\n",
    "      self.build_model()\n",
    "    return self.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ea1695-9fe3-41dd-bcd5-a34605372b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "noantiover = ModelProviderNoAntiOverfitting(nfeatures=9)\n",
    "nao_model = noantiover.get_model()\n",
    "nao_model_checkpoint_path =  f\"/net/tscratch/people/plgjsikora/models/MLSTM_athena_final_noantiover_{today}.weights.h5\"\n",
    "nao_model_checkpoint = ModelCheckpoint(nao_model_checkpoint_path, verbose=1, mode='auto',\n",
    "                                       monitor='val_accuracy', save_best_only=True, save_weights_only=True)\n",
    "\n",
    "optm = Adam(learning_rate=5e-4)\n",
    "\n",
    "callback_list = [nao_model_checkpoint]\n",
    "nao_model.compile(optimizer=optm, loss='categorical_crossentropy',  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f08eb73-d066-4192-aa84-7717bde3d2df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#nao_history = nao_model.fit(x_train, y_train, batch_size=256, epochs=50, verbose=1, shuffle=True, callbacks=callback_list, validation_freq=1, validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29241446-9a14-4413-bd6c-27b330601207",
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open(f'/net/tscratch/people/plgjsikora/naohist150epochs_{today}.pickle', 'wb') as file_pi:\n",
    "    #pickle.dump(nao_history.history, file_pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fad1d5a-e0b3-4178-9b15-d0efb68b364f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ao = ModelProvider(nfeatures = 9)\n",
    "#ao_bestmodel = ao.from_weights(\"/net/tscratch/people/plgjsikora/models/MLSTM_athena_final2025-06-21.weights.h5\")\n",
    "#preds = ao_bestmodel.predict(x_t)\n",
    "nao = ModelProviderNoAntiOverfitting(nfeatures = 9)\n",
    "nao_bestmodel = nao.from_weights(f\"/net/tscratch/people/plgjsikora/models/MLSTM_athena_final_noantiover_{today}.weights.h5\")\n",
    "naopreds = nao_bestmodel.predict(x_t)\n",
    "#np.save(f\"/net/tscratch/people/plgjsikora/aopreds_{today}.npy\", preds)\n",
    "np.save(f\"/net/tscratch/people/plgjsikora/naopreds_{today}.npy\", naopreds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93177bdf-6c72-41e4-ba3d-911b7b27f99a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12905d7d-44b5-4e6c-b6a6-9f65b0745962",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
